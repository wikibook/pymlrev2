{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 사전 처리(Preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "house_df_org = pd.read_csv('house_price.csv')\n",
    "house_df = house_df_org.copy()\n",
    "house_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('데이터 세트의 Shape:', house_df.shape)\n",
    "print('\\n전체 feature 들의 type \\n',house_df.dtypes.value_counts())\n",
    "isnull_series = house_df.isnull().sum()\n",
    "print('\\nNull 컬럼과 그 건수:\\n ', isnull_series[isnull_series > 0].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.title('Original Sale Price Histogram')\n",
    "plt.xticks(rotation=15)\n",
    "sns.histplot(house_df['SalePrice'], kde=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.title('Log Transformed Sale Price Histogram')\n",
    "log_SalePrice = np.log1p(house_df['SalePrice'])\n",
    "sns.histplot(log_SalePrice, kde=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SalePrice 로그 변환\n",
    "original_SalePrice = house_df['SalePrice']\n",
    "house_df['SalePrice'] = np.log1p(house_df['SalePrice'])\n",
    "\n",
    "# Null 이 너무 많은 컬럼들과 불필요한 컬럼 삭제\n",
    "house_df.drop(['Id','PoolQC' , 'MiscFeature', 'Alley', 'Fence','FireplaceQu'], axis=1 , inplace=True)\n",
    "# Drop 하지 않는 숫자형 Null컬럼들은 평균값으로 대체\n",
    "house_df.fillna(house_df.mean(),inplace=True)\n",
    "\n",
    "# Null 값이 있는 피처명과 타입을 추출\n",
    "null_column_count = house_df.isnull().sum()[house_df.isnull().sum() > 0]\n",
    "print('## Null 피처의 Type :\\n', house_df.dtypes[null_column_count.index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('get_dummies() 수행 전 데이터 Shape:', house_df.shape)\n",
    "house_df_ohe = pd.get_dummies(house_df)\n",
    "print('get_dummies() 수행 후 데이터 Shape:', house_df_ohe.shape)\n",
    "\n",
    "null_column_count = house_df_ohe.isnull().sum()[house_df_ohe.isnull().sum() > 0]\n",
    "print('## Null 피처의 Type :\\n', house_df_ohe.dtypes[null_column_count.index])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 선형 회귀 모델의 학습/예측/평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rmse(model):\n",
    "    pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test , pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print('{0} 로그 변환된 RMSE: {1}'.format(model.__class__.__name__,np.round(rmse, 3)))\n",
    "    return rmse\n",
    "\n",
    "def get_rmses(models):\n",
    "    rmses = [ ]\n",
    "    for model in models:\n",
    "        rmse = get_rmse(model)\n",
    "        rmses.append(rmse)\n",
    "    return rmses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_target = house_df_ohe['SalePrice']\n",
    "X_features = house_df_ohe.drop('SalePrice',axis=1, inplace=False)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y_target, test_size=0.2, random_state=156)\n",
    "\n",
    "# LinearRegression, Ridge, Lasso 학습, 예측, 평가\n",
    "lr_reg = LinearRegression()\n",
    "lr_reg.fit(X_train, y_train)\n",
    "\n",
    "ridge_reg = Ridge()\n",
    "ridge_reg.fit(X_train, y_train)\n",
    "\n",
    "lasso_reg = Lasso()\n",
    "lasso_reg.fit(X_train, y_train)\n",
    "\n",
    "models = [lr_reg, ridge_reg, lasso_reg]\n",
    "get_rmses(models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_bottom_coef(model):\n",
    "    # coef_ 속성을 기반으로 Series 객체를 생성. index는 컬럼명. \n",
    "    coef = pd.Series(model.coef_, index=X_features.columns)\n",
    "    \n",
    "    # + 상위 10개 , - 하위 10개 coefficient 추출하여 반환.\n",
    "    coef_high = coef.sort_values(ascending=False).head(10)\n",
    "    coef_low = coef.sort_values(ascending=False).tail(10)\n",
    "    return coef_high, coef_low\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_coefficient(models):\n",
    "    # 3개 회귀 모델의 시각화를 위해 3개의 컬럼을 가지는 subplot 생성\n",
    "    fig, axs = plt.subplots(figsize=(24,10),nrows=1, ncols=3)\n",
    "    fig.tight_layout() \n",
    "    # 입력인자로 받은 list객체인 models에서 차례로 model을 추출하여 회귀 계수 시각화. \n",
    "    for i_num, model in enumerate(models):\n",
    "        # 상위 10개, 하위 10개 회귀 계수를 구하고, 이를 판다스 concat으로 결합. \n",
    "        coef_high, coef_low = get_top_bottom_coef(model)\n",
    "        coef_concat = pd.concat( [coef_high , coef_low] )\n",
    "        # 순차적으로 ax subplot에 barchar로 표현. 한 화면에 표현하기 위해 tick label 위치와 font 크기 조정. \n",
    "        axs[i_num].set_title(model.__class__.__name__+' Coeffiecents', size=25)\n",
    "        axs[i_num].tick_params(axis=\"y\",direction=\"in\", pad=-120)\n",
    "        for label in (axs[i_num].get_xticklabels() + axs[i_num].get_yticklabels()):\n",
    "            label.set_fontsize(22)\n",
    "        sns.barplot(x=coef_concat.values, y=coef_concat.index , ax=axs[i_num])\n",
    "\n",
    "# 앞 예제에서 학습한 lr_reg, ridge_reg, lasso_reg 모델의 회귀 계수 시각화.    \n",
    "models = [lr_reg, ridge_reg, lasso_reg]\n",
    "visualize_coefficient(models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def get_avg_rmse_cv(models):\n",
    "    for model in models:\n",
    "        # 분할하지 않고 전체 데이터로 cross_val_score( ) 수행. 모델별 CV RMSE값과 평균 RMSE 출력\n",
    "        rmse_list = np.sqrt(-cross_val_score(model, X_features, y_target,\n",
    "                                             scoring=\"neg_mean_squared_error\", cv = 5))\n",
    "        rmse_avg = np.mean(rmse_list)\n",
    "        print('\\n{0} CV RMSE 값 리스트: {1}'.format( model.__class__.__name__, np.round(rmse_list, 3)))\n",
    "        print('{0} CV 평균 RMSE 값: {1}'.format( model.__class__.__name__, np.round(rmse_avg, 3)))\n",
    "\n",
    "# 앞 예제에서 학습한 lr_reg, ridge_reg, lasso_reg 모델의 CV RMSE값 출력           \n",
    "models = [lr_reg, ridge_reg, lasso_reg]\n",
    "get_avg_rmse_cv(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def print_best_params(model, params):\n",
    "    grid_model = GridSearchCV(model, param_grid=params, \n",
    "                              scoring='neg_mean_squared_error', cv=5)\n",
    "    grid_model.fit(X_features, y_target)\n",
    "    rmse = np.sqrt(-1* grid_model.best_score_)\n",
    "    print('{0} 5 CV 시 최적 평균 RMSE 값: {1}, 최적 alpha:{2}'.format(model.__class__.__name__,\n",
    "                                        np.round(rmse, 4), grid_model.best_params_))\n",
    "    return grid_model.best_estimator_\n",
    "\n",
    "ridge_params = { 'alpha':[0.05, 0.1, 1, 5, 8, 10, 12, 15, 20] }\n",
    "lasso_params = { 'alpha':[0.001, 0.005, 0.008, 0.05, 0.03, 0.1, 0.5, 1,5, 10] }\n",
    "best_rige = print_best_params(ridge_reg, ridge_params)\n",
    "best_lasso = print_best_params(lasso_reg, lasso_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앞의 최적화 alpha값으로 학습데이터로 학습, 테스트 데이터로 예측 및 평가 수행. \n",
    "lr_reg = LinearRegression()\n",
    "lr_reg.fit(X_train, y_train)\n",
    "ridge_reg = Ridge(alpha=12)\n",
    "ridge_reg.fit(X_train, y_train)\n",
    "lasso_reg = Lasso(alpha=0.001)\n",
    "lasso_reg.fit(X_train, y_train)\n",
    "\n",
    "# 모든 모델의 RMSE 출력\n",
    "models = [lr_reg, ridge_reg, lasso_reg]\n",
    "get_rmses(models)\n",
    "\n",
    "# 모든 모델의 회귀 계수 시각화 \n",
    "models = [lr_reg, ridge_reg, lasso_reg]\n",
    "visualize_coefficient(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 데이터 왜곡 로그 변환 후 성능 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew\n",
    "\n",
    "# object가 아닌 숫자형 피처의 칼럼 index 객체 추출.\n",
    "features_index = house_df.dtypes[house_df.dtypes != 'object'].index\n",
    "# house_df에 칼럼 index를 [ ]로 입력하면 해당하는 칼럼 데이터 세트 반환. apply lambda로 skew( ) 호출\n",
    "skew_features = house_df[features_index].apply(lambda x : skew(x))\n",
    "# skew(왜곡) 정도가 1 이상인 칼럼만 추출.\n",
    "skew_features_top = skew_features[skew_features > 1]\n",
    "print(skew_features_top.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_df[skew_features_top.index] = np.log1p(house_df[skew_features_top.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skew가 높은 피처들을 로그 변환 했으므로 다시 원-핫 인코딩 적용 및 피처/타겟 데이터 셋 생성,\n",
    "house_df_ohe = pd.get_dummies(house_df)\n",
    "y_target = house_df_ohe['SalePrice']\n",
    "X_features = house_df_ohe.drop('SalePrice',axis=1, inplace=False)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y_target, test_size=0.2, random_state=156)\n",
    "\n",
    "# 피처들을 로그 변환 후 다시 최적 하이퍼 파라미터와 RMSE 출력\n",
    "ridge_params = { 'alpha':[0.05, 0.1, 1, 5, 8, 10, 12, 15, 20] }\n",
    "lasso_params = { 'alpha':[0.001, 0.005, 0.008, 0.05, 0.03, 0.1, 0.5, 1,5, 10] }\n",
    "best_ridge = print_best_params(ridge_reg, ridge_params)\n",
    "best_lasso = print_best_params(lasso_reg, lasso_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앞의 최적화 alpha값으로 학습데이터로 학습, 테스트 데이터로 예측 및 평가 수행. \n",
    "lr_reg = LinearRegression()\n",
    "lr_reg.fit(X_train, y_train)\n",
    "ridge_reg = Ridge(alpha=10)\n",
    "ridge_reg.fit(X_train, y_train)\n",
    "lasso_reg = Lasso(alpha=0.001)\n",
    "lasso_reg.fit(X_train, y_train)\n",
    "\n",
    "# 모든 모델의 RMSE 출력\n",
    "models = [lr_reg, ridge_reg, lasso_reg]\n",
    "get_rmses(models)\n",
    "\n",
    "# 모든 모델의 회귀 계수 시각화 \n",
    "models = [lr_reg, ridge_reg, lasso_reg]\n",
    "visualize_coefficient(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 이상치 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x = house_df_org['GrLivArea'], y = house_df_org['SalePrice'])\n",
    "plt.ylabel('SalePrice', fontsize=15)\n",
    "plt.xlabel('GrLivArea', fontsize=15)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GrLivArea와 SalePrice 모두 로그 변환되었으므로 이를 반영한 조건 생성. \n",
    "cond1 = house_df_ohe['GrLivArea'] > np.log1p(4000)\n",
    "cond2 = house_df_ohe['SalePrice'] < np.log1p(500000)\n",
    "outlier_index = house_df_ohe[cond1 & cond2].index\n",
    "\n",
    "print('아웃라이어 레코드 index :', outlier_index.values)\n",
    "print('아웃라이어 삭제 전 house_df_ohe shape:', house_df_ohe.shape)\n",
    "# DataFrame의 index를 이용하여 아웃라이어 레코드 삭제. \n",
    "house_df_ohe.drop(outlier_index , axis=0, inplace=True)\n",
    "print('아웃라이어 삭제 후 house_df_ohe shape:', house_df_ohe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_target = house_df_ohe['SalePrice']\n",
    "X_features = house_df_ohe.drop('SalePrice',axis=1, inplace=False)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y_target, test_size=0.2, random_state=156)\n",
    "\n",
    "ridge_params = { 'alpha':[0.05, 0.1, 1, 5, 8, 10, 12, 15, 20] }\n",
    "lasso_params = { 'alpha':[0.001, 0.005, 0.008, 0.05, 0.03, 0.1, 0.5, 1,5, 10] }\n",
    "best_ridge = print_best_params(ridge_reg, ridge_params)\n",
    "best_lasso = print_best_params(lasso_reg, lasso_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앞의 최적화 alpha값으로 학습데이터로 학습, 테스트 데이터로 예측 및 평가 수행. \n",
    "lr_reg = LinearRegression()\n",
    "lr_reg.fit(X_train, y_train)\n",
    "ridge_reg = Ridge(alpha=8)\n",
    "ridge_reg.fit(X_train, y_train)\n",
    "lasso_reg = Lasso(alpha=0.001)\n",
    "lasso_reg.fit(X_train, y_train)\n",
    "\n",
    "# 모든 모델의 RMSE 출력\n",
    "models = [lr_reg, ridge_reg, lasso_reg]\n",
    "get_rmses(models)\n",
    "\n",
    "# 모든 모델의 회귀 계수 시각화 \n",
    "models = [lr_reg, ridge_reg, lasso_reg]\n",
    "visualize_coefficient(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 회귀 트리 학습/예측/평가 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb_params = {'n_estimators':[1000]}\n",
    "xgb_reg = XGBRegressor(n_estimators=1000, learning_rate=0.05, \n",
    "                       colsample_bytree=0.5, subsample=0.8)\n",
    "best_xgb = print_best_params(xgb_reg, xgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "lgbm_params = {'n_estimators':[1000]}\n",
    "lgbm_reg = LGBMRegressor(n_estimators=1000, learning_rate=0.05, num_leaves=4, \n",
    "                         subsample=0.6, colsample_bytree=0.4, reg_lambda=10, n_jobs=-1)\n",
    "best_lgbm = print_best_params(lgbm_reg, lgbm_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델의 중요도 상위 20개의 피처명과 그때의 중요도값을 Series로 반환.\n",
    "def get_top_features(model):\n",
    "    ftr_importances_values = model.feature_importances_\n",
    "    ftr_importances = pd.Series(ftr_importances_values, index=X_features.columns  )\n",
    "    ftr_top20 = ftr_importances.sort_values(ascending=False)[:20]\n",
    "    return ftr_top20\n",
    "\n",
    "def visualize_ftr_importances(models):\n",
    "    # 2개 회귀 모델의 시각화를 위해 2개의 컬럼을 가지는 subplot 생성\n",
    "    fig, axs = plt.subplots(figsize=(24,10),nrows=1, ncols=2)\n",
    "    fig.tight_layout() \n",
    "    # 입력인자로 받은 list객체인 models에서 차례로 model을 추출하여 피처 중요도 시각화. \n",
    "    for i_num, model in enumerate(models):\n",
    "        # 중요도 상위 20개의 피처명과 그때의 중요도값 추출 \n",
    "        ftr_top20 = get_top_features(model)\n",
    "        axs[i_num].set_title(model.__class__.__name__+' Feature Importances', size=25)\n",
    "        #font 크기 조정.\n",
    "        for label in (axs[i_num].get_xticklabels() + axs[i_num].get_yticklabels()):\n",
    "            label.set_fontsize(22)\n",
    "        sns.barplot(x=ftr_top20.values, y=ftr_top20.index , ax=axs[i_num])\n",
    "\n",
    "# 앞 예제에서 print_best_params( )가 반환한 GridSearchCV로 최적화된 모델의 피처 중요도 시각화    \n",
    "models = [best_xgb, best_lgbm]\n",
    "visualize_ftr_importances(models)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 회귀 모델들의 예측 결과 혼합을 통한 최종 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rmse_pred(preds):\n",
    "    for key in preds.keys():\n",
    "        pred_value = preds[key]\n",
    "        mse = mean_squared_error(y_test , pred_value)\n",
    "        rmse = np.sqrt(mse)\n",
    "        print('{0} 모델의 RMSE: {1}'.format(key, rmse))\n",
    "\n",
    "# 개별 모델의 학습\n",
    "ridge_reg = Ridge(alpha=8)\n",
    "ridge_reg.fit(X_train, y_train)\n",
    "lasso_reg = Lasso(alpha=0.001)\n",
    "lasso_reg.fit(X_train, y_train)\n",
    "# 개별 모델 예측\n",
    "ridge_pred = ridge_reg.predict(X_test)\n",
    "lasso_pred = lasso_reg.predict(X_test)\n",
    "\n",
    "# 개별 모델 예측값 혼합으로 최종 예측값 도출\n",
    "pred = 0.4 * ridge_pred + 0.6 * lasso_pred\n",
    "preds = {'최종 혼합': pred,\n",
    "         'Ridge': ridge_pred,\n",
    "         'Lasso': lasso_pred}\n",
    "#최종 혼합 모델, 개별모델의 RMSE 값 출력\n",
    "get_rmse_pred(preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_reg = XGBRegressor(n_estimators=1000, learning_rate=0.05, \n",
    "                       colsample_bytree=0.5, subsample=0.8)\n",
    "lgbm_reg = LGBMRegressor(n_estimators=1000, learning_rate=0.05, num_leaves=4, \n",
    "                         subsample=0.6, colsample_bytree=0.4, reg_lambda=10, n_jobs=-1)\n",
    "xgb_reg.fit(X_train, y_train)\n",
    "lgbm_reg.fit(X_train, y_train)\n",
    "xgb_pred = xgb_reg.predict(X_test)\n",
    "lgbm_pred = lgbm_reg.predict(X_test)\n",
    "\n",
    "pred = 0.5 * xgb_pred + 0.5 * lgbm_pred\n",
    "preds = {'최종 혼합': pred,\n",
    "         'XGBM': xgb_pred,\n",
    "         'LGBM': lgbm_pred}\n",
    "        \n",
    "get_rmse_pred(preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 스태킹 모델을 통한 회귀 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# 개별 기반 모델에서 최종 메타 모델이 사용할 학습 및 테스트용 데이터를 생성하기 위한 함수. \n",
    "def get_stacking_base_datasets(model, X_train_n, y_train_n, X_test_n, n_folds ):\n",
    "    # 지정된 n_folds값으로 KFold 생성.\n",
    "    kf = KFold(n_splits=n_folds, shuffle=False)\n",
    "    #추후에 메타 모델이 사용할 학습 데이터 반환을 위한 넘파이 배열 초기화 \n",
    "    train_fold_pred = np.zeros((X_train_n.shape[0] ,1 ))\n",
    "    test_pred = np.zeros((X_test_n.shape[0],n_folds))\n",
    "    print(model.__class__.__name__ , ' model 시작 ')\n",
    "    \n",
    "    for folder_counter , (train_index, valid_index) in enumerate(kf.split(X_train_n)):\n",
    "        #입력된 학습 데이터에서 기반 모델이 학습/예측할 폴드 데이터 셋 추출 \n",
    "        print('\\t 폴드 세트: ',folder_counter,' 시작 ')\n",
    "        X_tr = X_train_n[train_index] \n",
    "        y_tr = y_train_n[train_index] \n",
    "        X_te = X_train_n[valid_index]  \n",
    "        \n",
    "        #폴드 세트 내부에서 다시 만들어진 학습 데이터로 기반 모델의 학습 수행.\n",
    "        model.fit(X_tr , y_tr)       \n",
    "        #폴드 세트 내부에서 다시 만들어진 검증 데이터로 기반 모델 예측 후 데이터 저장.\n",
    "        train_fold_pred[valid_index, :] = model.predict(X_te).reshape(-1,1)\n",
    "        #입력된 원본 테스트 데이터를 폴드 세트내 학습된 기반 모델에서 예측 후 데이터 저장. \n",
    "        test_pred[:, folder_counter] = model.predict(X_test_n)\n",
    "            \n",
    "    # 폴드 세트 내에서 원본 테스트 데이터를 예측한 데이터를 평균하여 테스트 데이터로 생성 \n",
    "    test_pred_mean = np.mean(test_pred, axis=1).reshape(-1,1)    \n",
    "    \n",
    "    #train_fold_pred는 최종 메타 모델이 사용하는 학습 데이터, test_pred_mean은 테스트 데이터\n",
    "    return train_fold_pred , test_pred_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get_stacking_base_datasets( )은 넘파이 ndarray를 인자로 사용하므로 DataFrame을 넘파이로 변환. \n",
    "X_train_n = X_train.values\n",
    "X_test_n = X_test.values\n",
    "y_train_n = y_train.values\n",
    "\n",
    "# 각 개별 기반(Base)모델이 생성한 학습용/테스트용 데이터 반환. \n",
    "ridge_train, ridge_test = get_stacking_base_datasets(ridge_reg, X_train_n, y_train_n, X_test_n, 5)\n",
    "lasso_train, lasso_test = get_stacking_base_datasets(lasso_reg, X_train_n, y_train_n, X_test_n, 5)\n",
    "xgb_train, xgb_test = get_stacking_base_datasets(xgb_reg, X_train_n, y_train_n, X_test_n, 5)  \n",
    "lgbm_train, lgbm_test = get_stacking_base_datasets(lgbm_reg, X_train_n, y_train_n, X_test_n, 5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개별 모델이 반환한 학습 및 테스트용 데이터 세트를 Stacking 형태로 결합.  \n",
    "Stack_final_X_train = np.concatenate((ridge_train, lasso_train, \n",
    "                                      xgb_train, lgbm_train), axis=1)\n",
    "Stack_final_X_test = np.concatenate((ridge_test, lasso_test, \n",
    "                                     xgb_test, lgbm_test), axis=1)\n",
    "\n",
    "# 최종 메타 모델은 라쏘 모델을 적용. \n",
    "meta_model_lasso = Lasso(alpha=0.0005)\n",
    "\n",
    "#기반 모델의 예측값을 기반으로 새롭게 만들어진 학습 및 테스트용 데이터로 예측하고 RMSE 측정.\n",
    "meta_model_lasso.fit(Stack_final_X_train, y_train)\n",
    "final = meta_model_lasso.predict(Stack_final_X_test)\n",
    "mse = mean_squared_error(y_test , final)\n",
    "rmse = np.sqrt(mse)\n",
    "print('스태킹 회귀 모델의 최종 RMSE 값은:', rmse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
