{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 셋 로딩과 데이터 클린징"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "retail_df = pd.read_excel(io='Online Retail.xlsx')\n",
    "retail_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail_df = retail_df[retail_df['Quantity'] > 0]\n",
    "retail_df = retail_df[retail_df['UnitPrice'] > 0]\n",
    "retail_df = retail_df[retail_df['CustomerID'].notnull()]\n",
    "print(retail_df.shape)\n",
    "retail_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail_df['Country'].value_counts()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail_df = retail_df[retail_df['Country']=='United Kingdom']\n",
    "print(retail_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFM 기반 데이터 가공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail_df['sale_amount'] = retail_df['Quantity'] * retail_df['UnitPrice']\n",
    "retail_df['CustomerID'] = retail_df['CustomerID'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(retail_df['CustomerID'].value_counts().head(5))\n",
    "print(retail_df.groupby('CustomerID')['sale_amount'].sum().sort_values(ascending=False)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail_df.groupby(['InvoiceNo','StockCode'])['InvoiceNo'].count().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame의 groupby() 의 multiple 연산을 위해 agg() 이용\n",
    "# Recency는 InvoiceDate 컬럼의 max() 에서 데이터 가공\n",
    "# Frequency는 InvoiceNo 컬럼의 count() , Monetary value는 sale_amount 컬럼의 sum()\n",
    "aggregations = {\n",
    "    'InvoiceDate': 'max',\n",
    "    'InvoiceNo': 'count',\n",
    "    'sale_amount':'sum'\n",
    "}\n",
    "cust_df = retail_df.groupby('CustomerID').agg(aggregations)\n",
    "# groupby된 결과 컬럼값을 Recency, Frequency, Monetary로 변경\n",
    "cust_df = cust_df.rename(columns = {'InvoiceDate':'Recency',\n",
    "                                    'InvoiceNo':'Frequency',\n",
    "                                    'sale_amount':'Monetary'\n",
    "                                   }\n",
    "                        )\n",
    "cust_df = cust_df.reset_index()\n",
    "cust_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "cust_df['Recency'] = dt.datetime(2011,12,10) - cust_df['Recency']\n",
    "cust_df['Recency'] = cust_df['Recency'].apply(lambda x: x.days+1)\n",
    "print('cust_df 로우와 컬럼 건수는 ',cust_df.shape)\n",
    "cust_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFM 기반 고객 세그먼테이션"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2,ax3) = plt.subplots(figsize=(12,4), nrows=1, ncols=3)\n",
    "ax1.set_title('Recency Histogram')\n",
    "ax1.hist(cust_df['Recency'])\n",
    "\n",
    "ax2.set_title('Frequency Histogram')\n",
    "ax2.hist(cust_df['Frequency'])\n",
    "\n",
    "ax3.set_title('Monetary Histogram')\n",
    "ax3.hist(cust_df['Monetary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_df[['Recency','Frequency','Monetary']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "\n",
    "X_features = cust_df[['Recency','Frequency','Monetary']].values\n",
    "X_features_scaled = StandardScaler().fit_transform(X_features)\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, random_state=0)\n",
    "labels = kmeans.fit_predict(X_features_scaled)\n",
    "cust_df['cluster_label'] = labels\n",
    "\n",
    "print('실루엣 스코어는 : {0:.3f}'.format(silhouette_score(X_features_scaled,labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 여러개의 클러스터링 갯수를 List로 입력 받아 각각의 실루엣 계수를 면적으로 시각화한 함수 작성  \n",
    "def visualize_silhouette(cluster_lists, X_features): \n",
    "    \n",
    "    from sklearn.datasets import make_blobs\n",
    "    from sklearn.cluster import KMeans\n",
    "    from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.cm as cm\n",
    "    import math\n",
    "    \n",
    "    # 입력값으로 클러스터링 갯수들을 리스트로 받아서, 각 갯수별로 클러스터링을 적용하고 실루엣 개수를 구함\n",
    "    n_cols = len(cluster_lists)\n",
    "    \n",
    "    # plt.subplots()으로 리스트에 기재된 클러스터링 만큼의 sub figures를 가지는 axs 생성 \n",
    "    fig, axs = plt.subplots(figsize=(4*n_cols, 4), nrows=1, ncols=n_cols)\n",
    "    \n",
    "    # 리스트에 기재된 클러스터링 갯수들을 차례로 iteration 수행하면서 실루엣 개수 시각화\n",
    "    for ind, n_cluster in enumerate(cluster_lists):\n",
    "        \n",
    "        # KMeans 클러스터링 수행하고, 실루엣 스코어와 개별 데이터의 실루엣 값 계산. \n",
    "        clusterer = KMeans(n_clusters = n_cluster, max_iter=500, random_state=0)\n",
    "        cluster_labels = clusterer.fit_predict(X_features)\n",
    "        \n",
    "        sil_avg = silhouette_score(X_features, cluster_labels)\n",
    "        sil_values = silhouette_samples(X_features, cluster_labels)\n",
    "        \n",
    "        y_lower = 10\n",
    "        axs[ind].set_title('Number of Cluster : '+ str(n_cluster)+'\\n' \\\n",
    "                          'Silhouette Score :' + str(round(sil_avg,3)) )\n",
    "        axs[ind].set_xlabel(\"The silhouette coefficient values\")\n",
    "        axs[ind].set_ylabel(\"Cluster label\")\n",
    "        axs[ind].set_xlim([-0.1, 1])\n",
    "        axs[ind].set_ylim([0, len(X_features) + (n_cluster + 1) * 10])\n",
    "        axs[ind].set_yticks([])  # Clear the yaxis labels / ticks\n",
    "        axs[ind].set_xticks([0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "        \n",
    "        # 클러스터링 갯수별로 fill_betweenx( )형태의 막대 그래프 표현. \n",
    "        for i in range(n_cluster):\n",
    "            ith_cluster_sil_values = sil_values[cluster_labels==i]\n",
    "            ith_cluster_sil_values.sort()\n",
    "            \n",
    "            size_cluster_i = ith_cluster_sil_values.shape[0]\n",
    "            y_upper = y_lower + size_cluster_i\n",
    "            \n",
    "            color = cm.nipy_spectral(float(i) / n_cluster)\n",
    "            axs[ind].fill_betweenx(np.arange(y_lower, y_upper), 0, ith_cluster_sil_values, \\\n",
    "                                facecolor=color, edgecolor=color, alpha=0.7)\n",
    "            axs[ind].text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "            y_lower = y_upper + 10\n",
    "            \n",
    "        axs[ind].axvline(x=sil_avg, color=\"red\", linestyle=\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 여러개의 클러스터링 갯수를 List로 입력 받아 각각의 클러스터링 결과를 시각화 \n",
    "def visualize_kmeans_plot_multi(cluster_lists, X_features):\n",
    "    \n",
    "    from sklearn.cluster import KMeans\n",
    "    from sklearn.decomposition import PCA\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    # plt.subplots()으로 리스트에 기재된 클러스터링 만큼의 sub figures를 가지는 axs 생성 \n",
    "    n_cols = len(cluster_lists)\n",
    "    fig, axs = plt.subplots(figsize=(4*n_cols, 4), nrows=1, ncols=n_cols)\n",
    "    \n",
    "    # 입력 데이터의 FEATURE가 여러개일 경우 2차원 데이터 시각화가 어려우므로 PCA 변환하여 2차원 시각화\n",
    "    pca = PCA(n_components=2)\n",
    "    pca_transformed = pca.fit_transform(X_features)\n",
    "    dataframe = pd.DataFrame(pca_transformed, columns=['PCA1','PCA2'])\n",
    "    \n",
    "     # 리스트에 기재된 클러스터링 갯수들을 차례로 iteration 수행하면서 KMeans 클러스터링 수행하고 시각화\n",
    "    for ind, n_cluster in enumerate(cluster_lists):\n",
    "        \n",
    "        # KMeans 클러스터링으로 클러스터링 결과를 dataframe에 저장. \n",
    "        clusterer = KMeans(n_clusters = n_cluster, max_iter=500, random_state=0)\n",
    "        cluster_labels = clusterer.fit_predict(pca_transformed)\n",
    "        dataframe['cluster']=cluster_labels\n",
    "        \n",
    "        unique_labels = np.unique(clusterer.labels_)\n",
    "        markers=['o', 's', '^', 'x', '*']\n",
    "       \n",
    "        # 클러스터링 결과값 별로 scatter plot 으로 시각화\n",
    "        for label in unique_labels:\n",
    "            label_df = dataframe[dataframe['cluster']==label]\n",
    "            if label == -1:\n",
    "                cluster_legend = 'Noise'\n",
    "            else :\n",
    "                cluster_legend = 'Cluster '+str(label)           \n",
    "            axs[ind].scatter(x=label_df['PCA1'], y=label_df['PCA2'], s=70,\\\n",
    "                        edgecolor='k', marker=markers[label], label=cluster_legend)\n",
    "\n",
    "        axs[ind].set_title('Number of Cluster : '+ str(n_cluster))    \n",
    "        axs[ind].legend(loc='upper right')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_silhouette([2,3,4,5],X_features_scaled)\n",
    "visualize_kmeans_plot_multi([2,3,4,5],X_features_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Log 변환을 통해 데이터 변환\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "\n",
    "# Recency, Frequecny, Monetary 컬럼에 np.log1p() 로 Log Transformation\n",
    "cust_df['Recency_log'] = np.log1p(cust_df['Recency'])\n",
    "cust_df['Frequency_log'] = np.log1p(cust_df['Frequency'])\n",
    "cust_df['Monetary_log'] = np.log1p(cust_df['Monetary'])\n",
    "\n",
    "# Log Transformation 데이터에 StandardScaler 적용\n",
    "X_features = cust_df[['Recency_log','Frequency_log','Monetary_log']].values\n",
    "X_features_scaled = StandardScaler().fit_transform(X_features)\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, random_state=0)\n",
    "labels = kmeans.fit_predict(X_features_scaled)\n",
    "cust_df['cluster_label'] = labels\n",
    "\n",
    "print('실루엣 스코어는 : {0:.3f}'.format(silhouette_score(X_features_scaled,labels)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_silhouette([2,3,4,5],X_features_scaled)\n",
    "visualize_kmeans_plot_multi([2,3,4,5],X_features_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
